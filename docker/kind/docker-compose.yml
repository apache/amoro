
services:
  postgres:
    image: postgres:15
    container_name: amoro-postgres
    networks:
      iceberg-net:
    ports:
    - "5432:5432"
    environment:
      POSTGRES_USER: iceberg
      POSTGRES_PASSWORD: password
      POSTGRES_DB: iceberg
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "iceberg", "-d", "iceberg"]
      interval: 3s
      timeout: 10s
      retries: 10
      start_period: 30s
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data
    command: postgres -c max_connections=300

  minio:
    image: minio/minio:RELEASE.2025-04-03T14-56-28Z
    container_name: amoro-minio
    networks:
      iceberg-net:
        ipv4_address: 172.30.0.5
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password
      MINIO_DOMAIN: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./data/minio_data:/data
    command: ["server", "/data", "--console-address", ":9001"]

  mc:
    image: minio/mc:RELEASE.2025-04-03T17-07-56Z
    container_name: amoro-mc
    depends_on:
      - minio
    networks:
      iceberg-net:
    entrypoint:
      - /bin/sh
      - -c
      - |
        until /usr/bin/mc config host add minio http://minio:9000 admin password; do sleep 1; done
        /usr/bin/mc mb minio/warehouse --ignore-existing
        /usr/bin/mc anonymous set public minio/warehouse
        echo "MinIO bucket 'warehouse' is ready."

  kind-setup:
    image: docker:27-cli
    container_name: amoro-kind-setup
    networks:
      iceberg-net:
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - kind-kubeconfig:/output
      - ./kind-config.yaml:/kind-config.yaml:ro
      - ./spark-rbac.yaml:/spark-rbac.yaml:ro
    entrypoint:
      - /bin/sh
      - -c
      - |
        set -e

        echo "==> Installing kind..."
        apk add --no-cache curl >/dev/null 2>&1
        curl -sLo /usr/local/bin/kind https://kind.sigs.k8s.io/dl/v0.23.0/kind-linux-amd64
        chmod +x /usr/local/bin/kind

        echo "==> Creating Kind cluster (amoro-cluster)..."
        if kind get clusters 2>/dev/null | grep -q '^amoro-cluster$$'; then
          echo "   Cluster already exists, skipping creation."
        else
          kind create cluster --config /kind-config.yaml --wait 120s
        fi

        echo "==> Connecting Kind nodes to iceberg-net..."
        docker network connect iceberg-net amoro-cluster-control-plane 2>/dev/null || true
        for w in $$(docker ps --filter "name=amoro-cluster-worker" --format "{{.Names}}"); do
          docker network connect iceberg-net "$$w" 2>/dev/null || true
        done

        echo "==> Applying Spark RBAC (namespace + service account)..."
        cat /spark-rbac.yaml | docker exec -i amoro-cluster-control-plane \
          kubectl --kubeconfig /etc/kubernetes/admin.conf apply -f -

        echo "==> Generating kubeconfig for Amoro..."
        kind get kubeconfig --name amoro-cluster \
          | sed 's|server: .*|server: https://amoro-cluster-control-plane:6443|' \
          > /output/config
        chmod 644 /output/config

        echo "==> Kind setup complete!"

  # ---- Load Spark image into Kind workers (one-shot, parallel to Amoro) ----
  # Uses native docker save + ctr import — no kind binary needed.
  # Saves once, imports into worker nodes only (pods don't run on control-plane).
  kind-load-image:
    image: docker:27-cli
    container_name: amoro-kind-load-image
    depends_on:
      kind-setup:
        condition: service_completed_successfully
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    entrypoint:
      - /bin/sh
      - -c
      - |
        IMAGE="apache/amoro-spark-optimizer:latest"

        if ! docker image inspect $$IMAGE >/dev/null 2>&1; then
          echo "==> Image $$IMAGE not found locally — skipping."
          exit 0
        fi

        echo "==> Saving $$IMAGE to tarball (once)..."
        docker save $$IMAGE -o /tmp/spark-optimizer.tar
        echo "   Saved ($$(du -h /tmp/spark-optimizer.tar | cut -f1))."

        echo "==> Importing into Kind worker nodes..."
        for NODE in $$(docker ps --filter "name=amoro-cluster-worker" --format "{{.Names}}"); do
          echo "   Importing into $$NODE..."
          cat /tmp/spark-optimizer.tar | docker exec -i $$NODE ctr --namespace=k8s.io images import -
        done

        rm -f /tmp/spark-optimizer.tar
        echo "==> Done — image available on all workers."

  spark-copy:
    image: apache/amoro-spark-optimizer:latest
    container_name: amoro-spark-copy
    entrypoint:
      - /bin/sh
      - -c
      - |
        if [ -f /spark-vol/.done ]; then
          echo "Spark already copied — skipping."
        else
          echo "Copying Spark to shared volume..."
          cp -a /opt/spark/. /spark-vol/
          touch /spark-vol/.done
          echo "Spark copy complete."
        fi
    volumes:
      - spark-home:/spark-vol

  amoro:
    image: apache/amoro
    container_name: amoro
    depends_on:
      postgres:
        condition: service_healthy
      kind-setup:
        condition: service_completed_successfully
      spark-copy:
        condition: service_completed_successfully
    networks:
      iceberg-net:
        ipv4_address: 172.30.0.10
    ports:
      - "1630:1630"    # Web UI + REST API
      - "1260:1260"    # Thrift table service
      - "1261:1261"    # Thrift optimizing service
    environment:
      JVM_XMS: "1024"
      JVM_XMX: "2048"
      KUBECONFIG: /root/.kube/config
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password
    volumes:
      - ./config.yaml:/usr/local/amoro/conf/config.yaml:ro
      - kind-kubeconfig:/root/.kube:ro
      - spark-home:/opt/spark:ro
    command: ["/entrypoint.sh", "ams"]
    tty: true
    stdin_open: true

  amoro-init:
    image: curlimages/curl
    container_name: amoro-init
    depends_on:
      amoro:
        condition: service_started
      kind-load-image:
        condition: service_completed_successfully
    networks:
      iceberg-net:
    entrypoint:
      - /bin/sh
      - -c
      - |
        echo "Waiting for Amoro to be ready..."
        until curl -sf http://amoro:1630/ >/dev/null 2>&1; do sleep 2; done
        sleep 10

        echo "Logging in..."
        curl -sf -c /tmp/cookies.txt \
          -X POST http://amoro:1630/api/ams/v1/login \
          -H "Content-Type: application/json" \
          -H "X-Request-Source: Web" \
          -d '{"user":"admin","password":"admin"}'
        echo ""

        # ---- Optimizer Group (Spark on Kubernetes) ----
        echo "Checking optimizer group..."
        GROUPS=$$(curl -s -b /tmp/cookies.txt \
          -H "X-Request-Source: Web" \
          http://amoro:1630/api/ams/v1/optimize/resourceGroups)

        if echo "$$GROUPS" | grep -q '"name":"spark-container"'; then
          echo "  Optimizer group 'spark-container' already exists — skipping."
        else
          echo "  Creating optimizer group 'spark-container' (Spark on K8s)..."
          curl -s -b /tmp/cookies.txt \
            -X POST http://amoro:1630/api/ams/v1/optimize/resourceGroups \
            -H "Content-Type: application/json" \
            -H "X-Request-Source: Web" \
            -d '{"name":"spark-container","container":"sparkContainer","properties":{}}'
          echo ""
          sleep 5
        fi

        # ---- Optimizer (always ensure at least 1 is running) ----
        echo "Checking optimizers..."
        OPTIMIZERS=$$(curl -s -b /tmp/cookies.txt \
          -H "X-Request-Source: Web" \
          "http://amoro:1630/api/ams/v1/optimize/optimizerGroups/spark-container/optimizers?page=1&pageSize=10")

        if echo "$$OPTIMIZERS" | grep -q '"jobStatus":"RUNNING"'; then
          echo "  Spark optimizer already running — skipping."
        else
          echo "  Scaling out Spark optimizer (parallelism=1)..."
          curl -s -b /tmp/cookies.txt \
            -X POST http://amoro:1630/api/ams/v1/optimize/optimizerGroups/spark-container/optimizers \
            -H "Content-Type: application/json" \
            -H "X-Request-Source: Web" \
            -d '{"parallelism":1}'
          echo ""
          sleep 5
        fi

        # ---- Catalog ----
        echo "Checking catalog..."
        CATALOGS=$$(curl -s -b /tmp/cookies.txt \
          -H "X-Request-Source: Web" \
          http://amoro:1630/api/ams/v1/catalogs)

        if echo "$$CATALOGS" | grep -q '"catalogName":"olake_iceberg"'; then
          echo "  Catalog 'olake_iceberg' already exists — skipping."
        else
          echo "  Creating catalog 'olake_iceberg' (Iceberg JdbcCatalog on Postgres + MinIO)..."
          curl -s -b /tmp/cookies.txt \
            -X POST http://amoro:1630/api/ams/v1/catalogs \
            -H "Content-Type: application/json" \
            -H "X-Request-Source: Web" \
            -d '{
              "name":"olake_iceberg",
              "type":"custom",
              "optimizerGroup":"spark-container",
              "tableFormatList":["ICEBERG"],
              "storageConfig":{
                "storage.type":"S3",
                "storage.s3.endpoint":"http://172.30.0.5:9000",
                "storage.s3.region":"us-east-1"
              },
              "authConfig":{
                "auth.type":"AKSK",
                "auth.aksk.access-key":"admin",
                "auth.aksk.secret-key":"password"
              },
              "properties":{
                "catalog-impl":"org.apache.iceberg.jdbc.JdbcCatalog",
                "uri":"jdbc:postgresql://postgres:5432/iceberg",
                "jdbc.user":"iceberg",
                "jdbc.password":"password",
                "jdbc.driver":"org.postgresql.Driver",
                "jdbc.schema-version":"V1",
                "warehouse":"s3://warehouse/olake_iceberg/",
                "s3.path-style-access":"true",
                "io-impl":"org.apache.iceberg.aws.s3.S3FileIO",
                "endpoint":"http://172.30.0.5:9000",
                "access-key-id":"admin",
                "secret-access-key":"password"
              },
              "tableProperties":{}
            }'
          echo ""
        fi

        echo ""
        echo "============================================"
        echo "  Amoro is ready!"
        echo "  Web UI : http://localhost:1630"
        echo "  Login  : admin / admin"
        echo "  Catalog: olake_iceberg"
        echo "============================================"

networks:
  iceberg-net:
    driver: bridge
    name: iceberg-net
    ipam:
      config:
        - subnet: 172.30.0.0/24

volumes:
  kind-kubeconfig:
  spark-home: